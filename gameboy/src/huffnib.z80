include "src/global.inc"

def HUFFNIB_INCLUDE_TESTS equ 0
def WIDTHS_4BIT equ 1

; huffnib_bytecountlo is top of stack
def huffnib_bytecounthi equs "(help_line_buffer + 31)"
def huffnib_symboldefs equs "(help_line_buffer)"

section "huffnib", ROM0

;;
; Decoder for a canonical Huffman code
; code_lengths are in HRAM
; assume 23 mcycles per input bit plus 30 per symbol.
canohuff_decode_symbol:
  local hCodeLengths, 15
  local hBitAccum, 1
  ; Regmap:
  ; B  remaining bits in this byte of input
  ; C  pointer into bit lengths
  ; D  current code length
  ; E  range end (total number of code lengths so far)
  ; HL pointer to next byte of input

  ; 10 Set up Canonical Huffman state machine
  push de
  xor a
  ld e, a  ; E: range end
  ldh [.hBitAccum], a
  ld c, low(.hCodeLengths) - 1
.loop:
  ; 4 Fetch number of codes of this length
  inc c
  ldh a, [c]
  ld d, a  ; D: ncodesofthislength

  ; 2 Set range_end to the total number of codes seen so far,
  ; or the first index not representable by this many bits
  add e
  ld e, a
  
  ; ~6 Read a bit from the bit stream
  getbit

  ; 11 Add it to the bit accumulator and compare to available codes
  ; of this length
  ldh a, [.hBitAccum]
  adc a
  sub d
  ldh [.hBitAccum], a
  jr nc, .loop  ; If beyond available codes, keep getting more bits

  ; We have read a whole symbol.
  ; Here, A is negative.  It represents
  ;     bit accumulator - ncodesofthislength
  ; and E represents
  ;     first_index + ncodesofthislength
  ; Need to return bit accumulator + first_index
  ; which equals
  ;     (bit accumulator - ncodesofthislength) + (first_index + ncodesofthislength)
  ; that is, A + E
  ; Free because last jr was not taken
  add e

  ; 14 Translate to actual symbol through the
  ; "sorted by increasing code length" table
  ld de, huffnib_symboldefs
  add e
  ld e, a
  ld a, [de]
  pop de
  ret

;;
; Fills canohuff.hCodeLengths and symboldefs with compressed data header
; @param HL pointer to a canohuff block header
; @return HL updated to end of header; DE unchanged
canohuff_read_lengths:
  calls canohuff_decode_symbol  ; for its local variables

  ; So we have 3 to 16 distinct codes, with up to 13 of any given
  ; length, and the longest length shorter than the total number of
  ; codes.  Thus we can use code length $F as a terminator.
  ; Read (codes of this length, symbol) pairs until the terminator.
  push de  ; Save destination address
  lb bc, $80, low(canohuff_decode_symbol.hCodeLengths)  ; initialize state for getbit
  ld de, huffnib_symboldefs
.headerloop:
  ; Write symbols in order to huffnib_symboldefs
  ld a, [hl]
  and $0F
  ld [de], a
  inc de

  ; Write number of codes of each length
  ld a, [hl+]
  swap a
  and $0F
  ldh [c], a
  inc c
  cp $0F
  jr c, .headerloop

  pop de  ; Restore destination address
  ret

;;
; Decompresses the font if not yet decompressed
ensure_vwfInit::
  ld hl, help_font_loaded
  ld a, [hl]
  or a
  ret nz
  inc [hl]
  ld hl, vwfChrData_huf
  ld de, vwfChrData
  call huffnib_decode_compressed_block
  if WIDTHS_4BIT

    ; This is not ideal either, as the code to decode 1 symbol
    ; per byte is about as big as the code to unpack nibbles of
    ; uncompressed data.  If we need to unpack a stream of numbers
    ; 0-15 elsewhere in the Suite, look here for optimization.
    call canohuff_read_lengths
    ld a, [hl+]  ; should equal NUM_GLYPHS/2
    add a
    inc hl  ; skip lengths high
    .loop:
      push af
      call canohuff_decode_symbol
      ld [de], a
      inc de
      pop af
      dec a
      jr nz, .loop
    ret
  else

    ; This is not ideal (wasting 2 bits per glyph or 26 bytes) because
    ; all upper nibbles are automatically zero, but it was quick to do.
  
    ; hl and de are already in position after the last block
;    ld hl, vwfChrWidths_huf
;    ld de, vwfChrWidths
;    fallthrough huffnib_decode_block
  endc

;;
; I'm estimating 22 cycles per input bit and 74 per output byte.
; The largest known message is 10120 bits and 1538 bytes, or
; 337K cycles.
; @param HL start of interleaved code length counts and symbols,
; followed by length in bytes, followed by codes
; @param DE destination address
huffnib_decode_block::
  ; Upper nibbles are counts of codes of length 1-15.
  ; Lower nibbles are values for each code in increasing code length.
  ; In a valid Canonical Huffman code length table, the number of
  ; codes with length 1 can validly be only 3 things:
  ; 0: First code is at least 2 bits
  ; 1: First code is 1 bit, following codes are longer
  ; 2: Only 2 symbols exist
  ; 3+: Not possible. The encoder writes $FF for all symbols being
  ; 4-bit and nearly equiprobable, so just use memcpy.
  ld a, [hl+]
  cp $30
  jp nc, memcpy_pascal16
  dec hl
  fallthrough huffnib_decode_compressed_block

huffnib_decode_compressed_block::
  call canohuff_read_lengths
  ; Read length and negate it
  ld a, [hl+]
  cpl
  add 1
  push af  ; leave the length low byte on top of stack
  ld a, [hl+]
  cpl
  adc 0
  ld [huffnib_bytecounthi], a
.byteloop:
  ; 74+22n Decode two nibbles and combine them
  ; At this point:
  ; A = low byte of length upcounter, B = bits left in this byte,
  ; DE = destination, HL = source
  call canohuff_decode_symbol
  swap a
  ld [de], a
  call canohuff_decode_symbol
  ld c, a
  ld a, [de]
  or c
  ld [de], a
  inc de

  ; 10 go to next byte
  pop af
  inc a
  push af
  jr nz, .byteloop
  ld a, [huffnib_bytecounthi]
  inc a
  ld [huffnib_bytecounthi], a
  jr nz, .byteloop
  pop af
  ret

; Unused, untested non-canonical version ;;;;;;;;;;;;;;;;;;;;;;;;;;;;

  if 0  ; Not using non-canonical version
  
; 7654 3210  node format
; |||| ||++- offset in nodes to next 0 node
; |||| |+--- 01 node is literal
; |||| +---- 00 node is literal
; ||++------ offset in nodes to next 1 node
; |+-------- 11 node is literal
; +--------- 10 node is literal

; E bits 3-2 store the literalness
; BHL bit fetching

walk_huff_tree:
  push de
  ld c, low(hTree)
  ; Read initial literal bits from tree header
  ldh a, [c]
  and $0C  ; only initial literal bits matter
.get_next_node:
  ; A.1-0: offset to next node
  ; A.3: next node literal if 0; A.2: next node literal if 1
  ; 8 Read next tree node
  ld e, a
  and $03
  add c
  ld c, a
  inc c
  ldh a, [c]

  ; A: next node
  ; 10 Handle next bit
  getbit
  jr nc, .bit_was_0
  swap a
  rl e
.bit_was_0:

  ; A.3-0: current node
  ; E.3: current node is literal
  ; 5 test for literal
  bit 3, e
  jr z, .get_next_node

  and $0F
  pop de
  ret

  endc  ; End of unused non-canonical version

; Tests ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

  if HUFFNIB_INCLUDE_TESTS

huffnib_test::
  ld hl, huffnib_data1
  ld de, $8000
  call huffnib_decode_block
  ret

huffnib_data1:
  ; 00: 5, 01: 6, 10: 7, 110: 8, 111: 9
  db $05, $36, $27, $08, $F9
  dw 8
  ; 69 69 55 67 78 55 67 78
  db %01111011  ; 696[9
  db %11000001  ; 9]556
  db %10101100  ; 778[5
  db %00001101  ; 5]67[7
  db %01100000  ; 7]8|55

; TODO: Add more tests

  endc

; Directory ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; 0   0: use for both DMG and GBC; 1: use this for DMG and next for GBC
; 1   Additional data (such as PB16 tile count)
; 2-3 ROM address of start of Huffman data
; 4-5 WRAM address of start of unpacked data
; 6-7 ROM address of end of Huffman data (e.g. associated nametable)

;;
; Decodes all nibble-wise Huffman compressed data to WRAM
; at program start
allhuffdata_predecode::
  ld hl, allhuffdata_dir
.blockloop:

  ; Is this a pair of assets decoded to the same WRAM address,
  ; one for DMG and one for GBC?
  ld a, [hl+]  ; nonzero if DMG/GBC pair
  inc hl
  ld de, 14    ; distance to next entry after DMG half of DMG/GBC pair
  or a
  jr z, .not_gbc_pair

  ; DMG/GBC pair identifier nonzero means this is a GBC pair.
  ; Decompress this file if DMG or the next if GBC.
  ldh a, [hw_capability]  ; D7 set if GBC
  add a
  jr nc, .have_hl_de  ; DMG: Decode this entry and skip the next
.gbc_pair_is_gbc:
  ld e, 8     ; Skip to next entry
  add hl, de
.not_gbc_pair:
  ld e, 6     ; Decode this entry
.have_hl_de:

  ; HL: pointer to source field of this record
  ; DE: distance to start of next record
  push de
  push hl

  ; Load source and destination addresses
  ld a, [hl+]  ; BA: source
  ld b, [hl]
  inc hl
  ld e, [hl]   ; DE: destination
  inc hl
  ld d, [hl]
  ld h, b
  ld l, a
  call huffnib_decode_block

  ; Move to next block
  pop hl
  pop de
  add hl, de

  ; Get the next block
  ld a, l
  sub low(allhuffdata_dir_end)
  ld a, h
  sbc high(allhuffdata_dir_end)
  jr c, .blockloop
  ret

;;
; Fetches a predecoded file
; @param L file ID
; @return B: tile count; DE: decompressed data;
; HL: data following Huffman block
allhuffdata_fetch_file_l::
  ; Seek to the directory entry
  ld h, 0
  add hl, hl
  add hl, hl
  add hl, hl  ; HL: index into huffdir
  ld de, allhuffdata_dir
  add hl, de  ; HL: pointer to entry

  ; If this is a DMG/GBC pair, and this is a GBC,
  ; return the following entry
  ld a, [hl+]
  or a
  jr z, .not_gbc_pair
  ldh a, [hw_capability]
  add a
  jr nc, .not_gbc_pair
  ld de, 8
  add hl, de
.not_gbc_pair:

  ; Read bytes 1 (tile count), 4-5 (decompressed data pointer),
  ; and 6-7 (ancillary data pointer) from directory entry
  ld a, [hl+]
  ld b, a
  inc hl
  inc hl
  ld a, [hl+]
  ld e, a
  ld a, [hl+]
  ld d, a
  ld a, [hl+]
  ld h, [hl]
  ld l, a
  ret
